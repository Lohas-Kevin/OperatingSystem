[03/21/2019]


        CHECK OUT THESE URLS:

        http://apo.union.rpi.edu/mmoc/
        https://www.cs.rpi.edu/~goldsd/g.jpg



Project 1
-- Java problems were sorted out
-- new due date is 11:59PM Monday 3/25
   ^^^

Homework 3
-- Don't forget about this!

================================================================

Synchronization:
(1) data synchronization
(2) process/thread synchronization -- sequence of events


Multiple threads
-- in ONE process, we can have multiple threads of execution


             ONE PROCESS
  +---------------------------------+
  |           main()                |
  |             |                   |
  |             | int x = 5;        |
  |             v                   |
  |      create a few threads...    |
  |                                 |
  |                                 |
  | thread1   thread2     thread3   |
  |   |          |           |      |
  |   |         /            |      |
  |   |        |              \     |
  |  /          \              \    |
  | |            \              |   |
  | |             v             v   |
  | v                               |
  |                                 |
  | these threads join() back in    |
  |  to the parent thread           |
  |                                 |
  +---------------------------------+

The purpose behind joining threads back in to the parent thread:
-- we might want to return one or more values back from the child
    to the parent
-- we might want to ensure a specific sequence of events



Synchronization and Mutual Exclusion

  /* Process P1 or Thread T1 */
  while ( 1 )
  {
    execNonCriticalSection();
    execCriticalSection();
  }

  /* Process P2 or Thread T2 */
  while ( 1 )
  {
    execNonCriticalSection();
    execCriticalSection();
  }

  /* Process P3 or Thread T3 */
  while ( 1 )
  {
    execNonCriticalSection();
    execCriticalSection();
  }



                    /* global or shared memory */
                    int x = 5;
                    int lock = 0;  /* 0 == lock is available */

  /* Thread T1 */                      /* Thread T2 */
  while ( 1 )                          while ( 1 )
  {                                    {
    execNonCriticalSection();            execNonCriticalSection();
    while ( lock == 1 )                  while ( lock == 1 )
    {                                    {
      /* busy wait */                      /* busy wait */
    }                                    }
 --<context-switch>--
    lock = 1;                            lock = 1;
    execCriticalSection();               execCriticalSection();
    lock = 0;                            lock = 0;
  }                                    }

In the above solution, if a context switch occurs where shown,
 then both T1 and T2 can be in their critical sections at the same
  time (which is bad)


Below is a two-thread (or two-process) solution (Dekker's algorithm):

                    /* global or shared memory */
                    int x = 5;
                    int needLockT1 = 0;   /* 0 or 1 */
                    int needLockT2 = 0;   /* 0 or 1 */
                    int turn = T1;        /* T1 or T2 */

  /* Thread T1 */                      /* Thread T2 */
  while ( 1 )                          while ( 1 )
  {                                    {
    execNonCriticalSection();            execNonCriticalSection();
    needLockT1 = 1;                      needLockT2 = 1;
    turn = T2;                           turn = T1;

    while ( turn == T2 &&                while ( turn == T1 &&
            needLockT2 == 1 )                    needLockT1 == 1 )
    {                                    {
      /* busy wait */                      /* busy wait */
    }                                    }

    execCriticalSection();               execCriticalSection();
    needLockT1 = 0;                      needLockT2 = 0;
  }                                    }


T1: needLockT1 = 1;
T1: turn = T2;
T2: needLockT2 = 1;
T2: turn = T1;
T1: execCriticalSection();
T1: needLockT1 = 0;
T2: execCriticalSection();

TO DO: verify (convince yourself) that the above pseudocode will
        guarantee that only one thread is in its critical section
         at any given time

To DO: extend this to an n-thread solution


SEMAPHORE:

-- an OS construct that enables us to have synchronized access
    to one or more shared resources

-- special non-negative int variable

-- two operations:

   (1) first operation essentially attempts to gain access

       P()     proberen (to try)
       wait()
       down()

   (2) second operation relinquishes the access the acquired

       V()     vrijgeven (to release)
       signal()
       up()


  semaphore S is non-negative int variable

  P( semaphore S )     /* this P() operation MUST execute without    */
  {                    /*  any interruption, i.e., no context switch */
    while ( S == 0 )   /*   between exiting the while() loop and     */
    {                  /*    executing S--                           */
      /* busy wait */
    }
    S--;
  }

  V( semaphore S )
  {
    S++;
  }

-- example of a BINARY SEMAPHORE, which guarantees mutual exclusion

   /* initialize the semaphore to 1 since there is
       exactly one resource/lock */
   semaphore mutex = 1;

   /* each thread executes the code below: */
   ...
   P( mutex );
     executeCriticalSection();
   V( mutex );
   ...

-- a COUNTING (or GENERAL) SEMAPHORE controls access to a finite number
    of resources

   -- initialize the semaphore to n, where n is the number of
       resources to be shared/synchronized

      semaphore n = 20;

   -- again, we use the P() and V() operations;

   -- possible values of the semaphore are 0, 1, 2, ..., n


================================================================

-- this time we will look at the producer/consumer and shared buffer problems....


PRODUCER/CONSUMER PROBLEM (a.k.a. SHARED BUFFER PROBLEM)
-- Given a shared buffer (i.e., array) of a fixed size n
-- One or more producer threads
-- One or more consumer threads



                        /* shared/global memory */
                        int n = 20;
                        buffer[n];

  /* producer */                           /* consumer */
  while ( 1 )                              while ( 1 )
  {                                        {
    item = produce_next_item();              
                                             item = remove_from_buffer();
    add_to_buffer( item );                   
                                             consume( item );
  }                                        }



                        /* shared/global memory */
                        int n = 20;
                        buffer[n];
                        semaphore empty_slots = n;
                        semaphore used_slots = 0;

  /* producer */                           /* consumer */
  while ( 1 )                              while ( 1 )
  {                                        {
    item = produce_next_item();              P( used_slots );
    P( empty_slots );                          item = remove_from_buffer();
      add_to_buffer( item );                 V( empty_slots );
    V( used_slots );                         consume( item );
  }                                        }

  The above solution uses two counting semaphores to ensure:
  (1) no buffer overflow will occur in a producer
  (2) no reading from an empty buffer in the consumer


                        /* shared/global memory */
                        int n = 20;
                        buffer[n];
                        semaphore empty_slots = n;
                        semaphore used_slots = 0;
                        semaphore mutex = 1;

  /* producer */                           /* consumer */
  while ( 1 )                              while ( 1 )
  {                                        {
    item = produce_next_item();              P( used_slots );
    P( empty_slots );                          P( mutex );
      P( mutex );                                item = remove_from_buffer();
        add_to_buffer( item );                 V( mutex );
      V( mutex );                            V( empty_slots );
    V( used_slots );                         consume( item );
  }                                        }

TO DO: parallelize the above solution further such that reads/writes
         can occur simultaneously in different slots of the array

       P() is blocking operation

================================================================

Another related/similar example:

The READERS/WRITERS PROBLEM:

-- Shared resource is an array, e.g., seating chart of a flight or a concert
    or a Data Structures exam

-- One or more readers that can be reading simultaneously

-- One or more writers that actually reserve a seat
   -- When a writer wants to write, no other writers can be writing...
   -- When a writer wants to write, no readers can be reading...

================================================================

DINING PHILOSOPHERS PROBLEM

Given: five philosophers that engage in only two activities:
       -- thinking (i.e., independent computation)
       -- eating (i.e., sharing a resource; therefore, requires synchronization)

  philosopher( i )     /* i in 0..4 */
  {
    while ( 1 )
    {
      think()
      eat()
    }
  }

Given: shared table with five bowls and five chopsticks,
        and a bowl of food in the middle of the table
          (which is endlessly replenished)

Key contraint: to eat(), a philosopher must obtain two chopsticks,
                one from the left, one from the right

Goal: Design a solution by which you can guarantee that each
       philosopher eats; in order to eat, two chopsticks must
        be in hand

      No two philosophers can hold the same chopstick simultaneously

      Avoid deadlock

      No individual starvation

      Fairness, efficiency, etc.

Deadlock: We have deadlock when no process/thread can make any
           further progress (i.e., all blocked on P() operation
            and the given resource will NEVER become available)

First attempt:

  chopstick is array[5] of semaphores

  philosopher( i )     /* i in 0..4 */
  {
    while ( 1 )
    {
      think()
      P( chopstick[i] )
        P( chopstick[i+1%5] )
          eat()                 /* critical section */
        V( chopstick[i+1%5] )
      V( chopstick[i] )
    }
  }

Deadlock can occur if the first P() operation is successfully
 executed by each philosopher, followed immediately by a context switch
  -- no philosopher gets to their second P() operation
  -- therefore also no philosopher gets to their V() operation

A solution to this deadlock problem:
-- we could simply use a top-level mutex to avoid deadlock
   -- not efficient....

Second attempt:

  chopstick is array[5] of semaphores

  philosopher( i )     /* i in 0..4 */
  {
    while ( 1 )
    {
      think()
      P( mutex );
        P( chopstick[i] )
        P( chopstick[i+1%5] )
      V( mutex );
      eat()                 /* critical section */
      V( chopstick[i+1%5] )
      V( chopstick[i] )
    }
  }

  TO DO: convince yourself that the above solution "works," meaning
          that it avoids deadlock and is "fair" (or doesn't work)

Third attempt:

  -- use an asymmetric solution

  chopstick is array[5] of semaphores

  philosopher( i )     /* i in 0..3 (instead of i in 0..4) */
  {
    while ( 1 )
    {
      think()
      P( chopstick[i] )
        P( chopstick[i+1%5] )
          eat()                 /* critical section */
        V( chopstick[i+1%5] )
      V( chopstick[i] )
    }
  }

  philosopher( i )     /* i is always 4 */
  {
    while ( 1 )
    {
      think()
      P( chopstick[i+1%5] )    /* we swapped the order of the P() operations */
        P( chopstick[i] )
          eat()                 /* critical section */
        V( chopstick[i] )
      V( chopstick[i+1%5] )
    }
  }

  TO DO: convince yourself that the above solution "works," meaning
          that it avoids deadlock and is "fair" (or doesn't work)

================================================================

DEADLOCK

Deadlock: We have deadlock when no process/thread can make any
           further progress (i.e., all blocked on P() operation
            and the given resource will NEVER become available)

A system enters a deadlock state when multiple processes/threads
 are unable to obtain a lock on all necessary resources

  ...and therefore are unable to make any progress in their execution

After acquiring a resource, a process/thread holds onto that resource
 indefinitely (i.e., "hold and wait")

                semaphore S, Q

   // process 1                // process 2
   ...                         ...
   P( S ) [succeeds]           P( Q ) [succeeds]
   P( Q ) [block indef.]       P( S ) [block indefinitely]
   ...                         ...
   V( Q )                      V( S )
   V( S )                      V( Q )
   ...                         ...

Deadlock requires four conditions:
-- mutual exclusion
-- hold and wait
-- no preemption
-- circular wait -- i.e., a cycle in resource allocation graph

TO DO: does deadlock2.png portray a system that is deadlocked?

Handling deadlocks:
-- Allow the system to enter a deadlock state, then recover:
   -- terminating one or more of the deadlocked processes/threads
      (i.e., remove a vertex from the graph)
   -- rolling back one or more of the deadlocked processes/threads
       to a safe checkpointed state (i.e., remove an edge from the graph)

-- Another approach is to guarantee that the system will never
    enter a deadlock state:

   -- preventing deadlock ensures that at least one of the four conditions
       is never met
   -- deadlock avoidance allows a system to change state by
       allocating resources only when it is certain that
        deadlock will not occur as a result
