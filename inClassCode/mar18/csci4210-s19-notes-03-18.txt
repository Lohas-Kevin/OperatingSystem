[03/18/2019]

Project 1 specifications
-- new due date is 11:59PM Friday 3/22
   ^^^

Homework 3 -- multi-threaded assignment (in C using pthreads)
-- due date is 11:59PM Friday 3/29

================================================================

Synchronization:
(1) data synchronization
(2) process/thread synchronization -- sequence of events


Multiple threads
-- in ONE process, we can have multiple threads of execution


             ONE PROCESS
  +---------------------------------+
  |           main()                |
  |             |                   |
  |             | int x = 5;        |
  |             v                   |
  |      create a few threads...    |
  |                                 |
  |                                 |
  | thread1   thread2     thread3   |
  |   |          |           |      |
  |   |         /            |      |
  |   |        |              \     |
  |  /          \              \    |
  | |            \              |   |
  | |             v             v   |
  | v                               |
  |                                 |
  | these threads join() back in    |
  |  to the parent thread           |
  |                                 |
  +---------------------------------+

The purpose behind joining threads back in to the parent thread:
-- we might want to return one or more values back from the child
    to the parent
-- we might want to ensure a specific sequence of events



Synchronization and Mutual Exclusion

  /* Process P1 or Thread T1 */
  while ( 1 )
  {
    execNonCriticalSection();
    execCriticalSection();
  }

  /* Process P2 or Thread T2 */
  while ( 1 )
  {
    execNonCriticalSection();
    execCriticalSection();
  }

  /* Process P3 or Thread T3 */
  while ( 1 )
  {
    execNonCriticalSection();
    execCriticalSection();
  }



                    /* global or shared memory */
                    int x = 5;
                    int lock = 0;  /* 0 == lock is available */

  /* Thread T1 */                      /* Thread T2 */
  while ( 1 )                          while ( 1 )
  {                                    {
    execNonCriticalSection();            execNonCriticalSection();
    while ( lock == 1 )                  while ( lock == 1 )
    {                                    {
      /* busy wait */                      /* busy wait */
    }                                    }
 --<context-switch>--
    lock = 1;                            lock = 1;
    execCriticalSection();               execCriticalSection();
    lock = 0;                            lock = 0;
  }                                    }

In the above solution, if a context switch occurs where shown,
 then both T1 and T2 can be in their critical sections at the same
  time (which is bad)


Below is a two-thread (or two-process) solution (Dekker's algorithm):

                    /* global or shared memory */
                    int x = 5;
                    int needLockT1 = 0;   /* 0 or 1 */
                    int needLockT2 = 0;   /* 0 or 1 */
                    int turn = T1;        /* T1 or T2 */

  /* Thread T1 */                      /* Thread T2 */
  while ( 1 )                          while ( 1 )
  {                                    {
    execNonCriticalSection();            execNonCriticalSection();
    needLockT1 = 1;                      needLockT2 = 1;
    turn = T2;                           turn = T1;

    while ( turn == T2 &&                while ( turn == T1 &&
            needLockT2 == 1 )                    needLockT1 == 1 )
    {                                    {
      /* busy wait */                      /* busy wait */
    }                                    }

    execCriticalSection();               execCriticalSection();
    needLockT1 = 0;                      needLockT2 = 0;
  }                                    }


T1: needLockT1 = 1;
T1: turn = T2;
T2: needLockT2 = 1;
T2: turn = T1;
T1: execCriticalSection();
T1: needLockT1 = 0;
T2: execCriticalSection();

TO DO: verify (convince yourself) that the above pseudocode will
        guarantee that only one thread is in its critical section
         at any given time

To DO: extend this to an n-thread solution


SEMAPHORE:

-- an OS construct that enables us to have synchronized access
    to one or more shared resources

-- special non-negative int variable

-- two operations:

   (1) first operation essentially attempts to gain access

       P()     proberen (to try)
       wait()
       down()

   (2) second operation relinquishes the access the acquired

       V()     vrijgeven (to release)
       signal()
       up()


  semaphore S is non-negative int variable

  P( semaphore S )     /* this P() operation MUST execute without    */
  {                    /*  any interruption, i.e., no context switch */
    while ( S == 0 )   /*   between exiting the while() loop and     */
    {                  /*    executing S--                           */
      /* busy wait */
    }
    S--;
  }

  V( semaphore S )
  {
    S++;
  }

-- example of a BINARY SEMAPHORE, which guarantees mutual exclusion

   /* initialize the semaphore to 1 since there is
       exactly one resource/lock */
   semaphore mutex = 1;

   /* each thread executes the code below: */
   ...
   P( mutex );
     executeCriticalSection();
   V( mutex );
   ...

-- a COUNTING (or GENERAL) SEMAPHORE controls access to a finite number
    of resources

   -- initialize the semaphore to n, where n is the number of
       resources to be shared/synchronized

      semaphore n = 20;

   -- again, we use the P() and V() operations;

   -- possible values of the semaphore are 0, 1, 2, ..., n



-- next time we will look at the producer/consumer and shared buffer problems....





