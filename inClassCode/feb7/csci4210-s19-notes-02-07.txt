[02/07/2019]

=====================================================================

ps -ef | grep goldsd


 [PARENT]
    pipe() /* fd 3 is the read end; fd 4 is the write end */
    fork() /* ps */
    fork() /* grep */
    close( p[0] )
    close( p[1] )

 [CHILD ps]
 we want the output on stdout from ps to go to the write end of the pipe
 duplicate fd 4 into fd 1 (using dup2())
 exec( "ps", ... )

 [child grep]
 we want the input in stdin to be the read end of the pipe
 duplicate fd 3 into fd 0 (using dup2())
 exec( "grep", ... )


=====================================================================

FROM LAST TIME:

New jobs are admitted into the system
-- long-term or high-level scheduling

Once in the system, processes go through a number of state changes
-- short-term or low-level scheduling



A process is a "running program" or "program in execution"

Processes have a variety of states:


  RUNNING            READY                  WAITING (on I/O)
   STATE             STATE                   STATE

  +-----+                     ???<==P8   +---------------------+
  |     |     +---------------------     |                     |
  | CPU | <== | P3 | P5 | P2 | etc.      |  I/O subsystem      |
  | P12 |     +---------------------     |                     |
  +-----+                                +---------------------+

  RUNNING STATE: process is actively using the CPU
                 (i.e., executing/running its instructions)

  READY STATE: process is ready to use the CPU
               (i.e., idly waiting in the Ready Queue)

  WAITING STATE: process is waiting for I/O operation(s) to complete


 (job)      (process)
  NEW -----> READY ---------------> RUNNING ----------> TERMINATED
               ^                      |
               |                      |
               |                      |
               |                      v
               -------WAITING----------


CPU Scheduling (a.k.a. Short-Term Scheduling)

-- The scheduling system enables one process to use the CPU
    while other processes are waiting in the ready queue to
     use the CPU (or some are waiting for I/O)

-- The goals of CPU scheduling are to make the efficient use of the CPU
    and to minimize the turnaround and wait times for each running process

    -- We also want to achieve "fairness" among all processes
        to the extent possible

-- The job of the CPU Scheduler is, when the CPU becomes free,
    to select the next process from the ready queue

-- CPU Scheduling Algorithms:

   First Come First Served (FCFS)

   Shortest Job First (SJF)

   Shortest Remaining Time (SRT)

   Priority Scheduling

   Round Robin (RR)


-- Preemption occurs when the currently running process is
    preempted (i.e., "kicked out" or "replaced") from using the CPU

   -- might be because of a newly arriving (more important) process

   -- might be because of a timeout (i.e., the RR algorithm)


Processes in a multiprogramming system COMPETE for the CPU
 (but they also often need to COOPERATE with one another via IPC)


Whenever we switch a process out of the CPU and bring the next process
 in to use the CPU, we have a CONTEXT SWITCH

 -- the state of the currently running process is saved in
     a process control block (PCB), which includes registers,
      program counter, page table, memory maps

 -- the state of the next (or replacement) process is loaded from its PCB

            OVERHEAD !!!


Challenges of CPU scheduling include:
-- Processes alternate bursts of CPU time and I/O time;
    how do we best handle such processes and the process mix?

   +---------+ blocked +---------------------+   +-----------------+
P1 |CPU burst|---------|    CPU burst        |---|      CPU burst  |--->
   +---------+ on I/O  +---------------------+   +-----------------+

   +---+      blocked on I/O                    +---+
P2 |CPU|----------------------------------------|CPU|------------------>
   +---+                                        +---+


   P1 is a CPU-bound or compute-bound process,
    whereas P2 is an I/O-bound process

   We can model this as follows:
   -- Consider CPU usage from a probabilistic viewpoint
   -- Suppose processes spend fraction p of their time
       waiting for I/O to complete
   -- Given n processes in memory (i.e., the degree of multiprogramming is n),
       then the probability that all n processes are waiting for I/O is:

            n
           p

                                    n
   -- CPU utilization is then: 1 - p


-- Scheduling decisions:
-- When does the OS make a scheduling decision?
   -- fork() -- how do we schedule the child process?
   -- process termination
   -- process blocks on I/O (or enters a waiting/suspended state)
   -- I/O interrupt (does this cause a preemption)

-- Which process does the OS select next
    (i.e., how do we order the ready queue?)


-- The above depends on the "environment" (types of processes)

   -- batch: no users are waiting  (lower priority -- non-preemptive)

   -- interactive: users are waiting for a (quick) response; also
       servers serving up a file/webpage/etc.  (higher priority -- preemptive)

   -- real-time: preemption not usually necessary because processes
       already are designed to "know" that they need to run quickly


All types of process:
-- fairness
-- balance

Batch systems:
-- Throughput -- maximize jobs completed per unit time
-- Turnaround time -- minimize time between arrival and completion
-- CPU utilization -- keep CPU as busy as possible

Interactive systems:
-- Response time -- respond to user requests quickly



For each CPU burst per process:

WAIT TIME: How much time does a process spend in the ready queue
           for its CPU burst?

TURNAROUND TIME: How much time is required for a process to complete
                 its CPU burst, from the time it enters the ready queue
                 through to when it completes its CPU burst


TURNAROUND TIME  =  WAIT TIME  +  CPU BURST TIME

TURNAROUND TIME  =  WAIT TIME  +  CPU BURST TIME  +  OVERHEAD
                                                    (context switches)


First Come First Served (FCFS)

   pid    CPU burst times      (Assume all processes arrive at time 0)
   P1       18 ms
   P2        3 ms
   P3        4 ms

   ready queue is ordered: P1 P2 P3

    context switch       context switches
       v                   v   v    v
       +-------------------+---+----+------------->
 FCFS: | P1                |P2 | P3 | ..........
       +-------------------+---+----+------------->
    t: 0                   18  21   25


       P1 has 0 wait time        P1 has 18 ms turnaround time
       P2 has 18 ms wait time    P2 has 21 ms turnaround time
       P3 has 21 ms wait time    P3 has 25 ms turnaround time

advantages: very simple; easy to implement; very low overhead

disadvantages: larger processes can cause long delays for shorter processes



Shortest Job First (SJF)

   pid    CPU burst times      (Assume all processes arrive at time 0)
   P1       18 ms
   P2        3 ms
   P3        4 ms

   ready queue: P2 P3 P1   (priority queue)

    context switches            context switch
       v   v    v                   v
       +---+----+-------------------+------------->
  SJF: |P2 | P3 | P1                | ........
       +---+----+-------------------+------------->
    t: 0   3    7                   25

       P1 has 7 ms wait time    P1 has 25 ms turnaround time
       P2 has 0 wait time       P2 has 3 ms turnaround time
       P3 has 3 ms wait time    P3 has 7 ms turnaround time

advantages: lower average wait/turnaround times versus FCFS
            good low turnaround times for interactive or I/O-bound processes

disadvantages: process with a large CPU burst time might end up
                facing INDEFINITE BLOCKING (i.e., takes a loooooooooong
                 time to get to use the CPU);   fairness?

               process with a large CPU burst time might end up
                facing STARVATION (i.e., the process is starved
                 because it NEVER has its time with the CPU)

               higher overhead versus FCFS (priority queue)

               we have no way of knowing ahead of time exactly what
                the CPU burst times will be for each process
                 (but we can predict......)


Both FCFS and SJF are non-preemptive algorithms
-- once a process is using the CPU for its CPU burst,
    it will continue using the CPU until the burst is complete

-- what if we added preemption to SJF?

   -- i.e., when new process B arrives, it can potentially preempt
       (replace) the currently running process A if B's CPU burst time
        is less than the remaining burst time for process A


Shortest Remaining Time (SRT)

   pid    CPU burst times       arrival time
   P1       18 ms                   0 ms
   P2        3 ms                   2 ms
   P3        4 ms                   3 ms
   P4        3 ms                   5 ms

   ready queue: P1

    context switches
       v  v   v   v    v              v
       +--+---+---+----+--------------+----------->
  SRT: |P1pP2 |P4 | P3 |  P1          | ......
       +--+---+---+----+--------------+----------->
    t: 0  2   5   8    12             28

  When P2 preempts P1 at time 2 ms, P1 is added back to the ready queue

   to do: calculate the wait and turnaround times for each process

      P1 has wait time of 10 ms and turnaround time of 28 ms
        (the wait time is the sum of all time spent in the ready queue
          during the end-to-end turnaround time for the process)

advantages: similar to SJF;
            perhaps better at getting I/O-bound/interactive processes
               through the CPU more quickly?

disadvantages: similar to SJF;
               P1 took even longer than in the previous example




Priority scheduling

-- Each process is assigned a priority based on:
   -- CPU burst times (e.g., SJF/SRT)   <== estimated...
   -- ratio of CPU to I/O activity (predicted/expected)
   -- system resource usage
   -- arbitrary or hard-coded

-- The process with the highest priority gets scheduled first

-- When multiple processes have the same priority, we need a tie-breaker,
    which is a secondary algorithm on that subset (e.g., just use FCFS)

-- We decide (ahead of time) whether the algorithm is preemptive or not

